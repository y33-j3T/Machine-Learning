{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The universal workflow of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the problem and assembling a dataset\n",
    "\n",
    "1. What will your input data be?\n",
    "2. What are you trying to predict?\n",
    "3. What type of problem are you facing?\n",
    "    - Binary classification\n",
    "    - Multiclass classification\n",
    "    - Scalar regression   \n",
    "    - Vector regression\n",
    "    - Multiclass, multilabel classification\n",
    "    - Clustering\n",
    "    - Generation\n",
    "    - Reinforcement learning\n",
    "    - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Be aware of hypotheses you make at this stage\n",
    "\n",
    "1. You hypothesize that your outputs can be predicted given your inputs.\n",
    "2. You hypothesize that your available data is sufficiently informative to learn the relationship between inputs and outputs\n",
    "\n",
    "Not all problems can be solved; just because you’ve assembled examples\n",
    "of inputs X and targets Y doesn’t mean X contains enough information to predict\n",
    "Y.\n",
    "\n",
    "Keep in mind that machine learning can only be used to memorize patterns that are present in your training data. You can only recognize what you’ve seen before. Using machine learning trained on past data to predict the future is making the assumption that the future will behave like the past. That often isn’t the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a measure of success\n",
    "\n",
    "- balanced-classification problems\n",
    "    - accuracy, ROC AUC, etc.\n",
    "- class-imbalanced problems\n",
    "    - precision, recall, etc.\n",
    "- ranking problems, multilabel classification\n",
    "    - average precision\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on an evaluation protocol\n",
    "- Hold-out validation\n",
    "- K-fold cross-validation\n",
    "- Iterated K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your data\n",
    "\n",
    "How to format your data? (assuming a deep neural network)\n",
    "- data formatted as tensors\n",
    "- values taken by tensors scaled to small values, ie. \\[-1, 1\\] or \\[0, 1\\]\n",
    "- data normalized if values in different ranges\n",
    "- feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a model that does better than a baseline\n",
    "\n",
    "Your goal is to achieve *statistical power* : to develop a model capable of beating a dumb baseline.\n",
    "\n",
    "Three key choices to make:\n",
    "1. Last-layer activation\n",
    "    - linear\n",
    "    - sigmoid\n",
    "    - softmax\n",
    "    - etc.\n",
    "2. Loss function\n",
    "    - binary_crossentropy\n",
    "    - mse\n",
    "    - etc.\n",
    "3. Optimization configuration\n",
    "    - rmsprop\n",
    "    - etc.\n",
    "\n",
    "Note that there isn't always a direct way to turn a metric into a loss function.\n",
    "\n",
    "Loss functions need to be:\n",
    "- computable given mini-batch of data (as little as a single data point)\n",
    "- differentiable (can't use backpropagation otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Choosing the right last-layer activation and loss function\n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Problem type</th>\n",
    "    <th>Last-layer activation</th>\n",
    "    <th>Loss function</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Binary classification</td>\n",
    "    <td>sigmoid</td>\n",
    "    <td>binary_crossentropy</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Multiclass, single-label classification</td>\n",
    "    <td>softmax</td>\n",
    "    <td>categorical_crossentropy</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Multiclass, multi-label classification</td>\n",
    "    <td>sigmoid</td>\n",
    "    <td>binary_crossentropy</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Regression to arbitrary values</td>\n",
    "    <td>None</td>\n",
    "    <td>mse</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Regression to values between 0 and 1</td>\n",
    "    <td>sigmoid</td>\n",
    "    <td>mse or binary_crossentropy</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up: developing a model that overfits\n",
    "\n",
    "To figure out how big a model you need, you must develop a model that overfits.\n",
    "\n",
    "1. Add layers.\n",
    "2. Make the layers bigger.\n",
    "3. Train for more epochs.\n",
    "\n",
    "Always monitor the training and validation loss, as well as any metrics you care about to know if overfitting is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing your model and tuning your hyperparameters\n",
    "\n",
    "- Add dropout\n",
    "- Add L1 and/or L2 regularization\n",
    "- Try different architectures: add / remove layers\n",
    "- Try different hyperparameters\n",
    "    - units per layer\n",
    "    - learning rate\n",
    "    - etc.\n",
    "- Iterate on feature engineering\n",
    "\n",
    "**Note**: Using feedback from your validation process to tune your model over many iterations may cause the model to overfit to the validation process.\n",
    "\n",
    "**Note**: If the performance on the test set is significantly worse than the one on validation data, this may mean either that your **validation process wasn't reliable** or your **model had overfitted to the validation process**. (Switch to a more reliable evaluation protocol, eg. k-fold validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
